# SouhuSpider
爬取搜狐网站的新闻等内容

--直接运行Sohu.py文件
环境要求
  --requests
  --BeautifulSoup
  --lxml
  --selenuim
逆向分析网页的动态效果来源但是没能成功(成功版本之后更新)，选择了用selenuim包模拟浏览器下拉效果来实现下拉10次的爬取
目前是从搜狐首页'https://www.sohu.com//'爬取分类页面的类型和对应的分类页url，然后再一级一级的爬取文章的标题，发布时间，作者 ，正文，以及稳重可能包含的图片
因为自己对爬虫的研究不多，所以最初是对每个分类网页的内容进行分析，写针对每个网页的相关代码，分析了几个网页后发现太慢了，就使用了较为暴力的方法进行爬取
主要爬取的是包含文本以及图片的内容，由于搜狐分类涉及的东西过多，没有对每个类别仔细研究
最终是能爬取每个分类页面的文本类(包括图片)信息，没对网页的内容进行递归爬取(太大，而且需要去重避免死循环)
